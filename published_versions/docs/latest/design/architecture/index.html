<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-design/architecture">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Design | Apache® Druid</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://druid.apache.org/img/druid_nav.png"><meta data-rh="true" name="twitter:image" content="https://druid.apache.org/img/druid_nav.png"><meta data-rh="true" property="og:url" content="https://druid.apache.org/docs/latest/design/architecture"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Design | Apache® Druid"><meta data-rh="true" name="description" content="&lt;!--"><meta data-rh="true" property="og:description" content="&lt;!--"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://druid.apache.org/docs/latest/design/architecture"><link data-rh="true" rel="alternate" href="https://druid.apache.org/docs/latest/design/architecture" hreflang="en"><link data-rh="true" rel="alternate" href="https://druid.apache.org/docs/latest/design/architecture" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131010415-1"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-131010415-1",{})</script>




<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js"></script><link rel="stylesheet" href="/assets/css/styles.546f39eb.css">
<link rel="preload" href="/assets/js/runtime~main.91da3985.js" as="script">
<link rel="preload" href="/assets/js/main.1f0e5e69.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbar--dark"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/druid_nav.png" alt="Apache® Druid" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/druid_nav.png" alt="Apache® Druid" class="themedImage_ToTc themedImage--dark_i4oU"></div></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/technology">Technology</a><a class="navbar__item navbar__link" href="/use-cases">Use Cases</a><a class="navbar__item navbar__link" href="/druid-powered">Powered By</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/latest/design/">Docs</a><a class="navbar__item navbar__link" href="/community/">Community</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Apache®</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://apachecon.com/?ref=druid.apache.org" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a class="navbar__item navbar__link" href="/downloads/">Download</a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/design/">Getting started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/tutorials/tutorial-msq-extern">Tutorials</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/latest/design/architecture">Design</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/design/architecture">Design</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/design/segments">Segments</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/design/processes">Processes and servers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/design/deep-storage">Deep storage</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/design/metadata-storage">Metadata storage</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/design/zookeeper">ZooKeeper</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/ingestion/">Ingestion</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/data-management/">Data management</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/querying/sql">Querying</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/api-reference/">API reference</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/configuration/">Configuration</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/operations/web-console">Operations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/development/overview">Development</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/misc/papers-and-talks">Misc</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/latest/release-info/release-notes">Release info</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Design</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Design</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Design</h1></header><p>Druid has a distributed architecture that is designed to be cloud-friendly and easy to operate. You can configure and scale services independently so you have maximum flexibility over cluster operations. This design includes enhanced fault tolerance: an outage of one component does not immediately affect other components.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="druid-architecture">Druid architecture<a href="#druid-architecture" class="hash-link" aria-label="Direct link to Druid architecture" title="Direct link to Druid architecture">​</a></h2><p>The following diagram shows the services that make up the Druid architecture, how they are typically organized into servers, and how queries and data flow through this architecture.</p><p><img loading="lazy" alt="Druid architecture" src="/assets/images/druid-architecture-c89f21addd50d76d07dbc3a730cd856f.png" width="1920" height="1080" class="img_ev3q"></p><p>The following sections describe the components of this architecture. </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="druid-services">Druid services<a href="#druid-services" class="hash-link" aria-label="Direct link to Druid services" title="Direct link to Druid services">​</a></h2><p>Druid has several types of services:</p><ul><li><a href="/docs/latest/design/coordinator"><strong>Coordinator</strong></a> service manages data availability on the cluster.</li><li><a href="/docs/latest/design/overlord"><strong>Overlord</strong></a> service controls the assignment of data ingestion workloads.</li><li><a href="/docs/latest/design/broker"><strong>Broker</strong></a> handles queries from external clients.</li><li><a href="/docs/latest/design/router"><strong>Router</strong></a> services are optional; they route requests to Brokers, Coordinators, and Overlords.</li><li><a href="/docs/latest/design/historical"><strong>Historical</strong></a> services store queryable data.</li><li><a href="/docs/latest/design/middlemanager"><strong>MiddleManager</strong></a> services ingest data.</li></ul><p>You can view services in the <strong>Services</strong> tab in the web console: </p><p><img loading="lazy" alt="Druid services" src="/assets/images/services-overview-626a864a11edcf4945591a35d4a3814c.png" title="Services in the web console" width="1250" height="640" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="druid-servers">Druid servers<a href="#druid-servers" class="hash-link" aria-label="Direct link to Druid servers" title="Direct link to Druid servers">​</a></h2><p>Druid services can be deployed any way you like, but for ease of deployment we suggest organizing them into three server types: Master, Query, and Data.</p><ul><li><strong>Master</strong>: Runs Coordinator and Overlord processes, manages data availability and ingestion.</li><li><strong>Query</strong>: Runs Broker and optional Router processes, handles queries from external clients.</li><li><strong>Data</strong>: Runs Historical and MiddleManager processes, executes ingestion workloads and stores all queryable data.</li></ul><p>For more details on process and server organization, please see <a href="/docs/latest/design/processes">Druid Processes and Servers</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="external-dependencies">External dependencies<a href="#external-dependencies" class="hash-link" aria-label="Direct link to External dependencies" title="Direct link to External dependencies">​</a></h2><p>In addition to its built-in process types, Druid also has three external dependencies. These are intended to be able to
leverage existing infrastructure, where present.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="deep-storage">Deep storage<a href="#deep-storage" class="hash-link" aria-label="Direct link to Deep storage" title="Direct link to Deep storage">​</a></h3><p>Druid uses deep storage to store any data that has been ingested into the system. Deep storage is shared file
storage accessible by every Druid server. In a clustered deployment, this is typically a distributed object store like S3 or
HDFS, or a network mounted filesystem. In a single-server deployment, this is typically local disk.</p><p>Druid uses deep storage for the following purposes:</p><ul><li>To store all the data you ingest. Segments that get loaded onto Historical processes for low latency queries are also kept in deep storage for backup purposes. Additionally, segments that are only in deep storage can be used for <a href="/docs/latest/querying/query-deep-storage">queries from deep storage</a>.</li><li>As a way to transfer data in the background between Druid processes. Druid stores data in files called <em>segments</em>.</li></ul><p>Historical processes cache data segments on local disk and serve queries from that cache as well as from an in-memory cache.
Segments on disk for Historical processes provide the low latency querying performance Druid is known for.</p><p>You can also query directly from deep storage. When you query segments that exist only in deep storage, you trade some performance  for the ability to query more of your data without necessarily having to scale your Historical processes.</p><p>When determining sizing for your storage, keep the following in mind:</p><ul><li>Deep storage needs to be able to hold all the data that you ingest into Druid.</li><li>On disk storage for Historical processes need to be able to accommodate the data you want to load onto them to run queries. The data on Historical processes should be data you access frequently and need to run low latency queries for. </li></ul><p>Deep storage is an important part of Druid&#x27;s elastic, fault-tolerant design. Druid bootstraps from deep storage even
if every single data server is lost and re-provisioned.</p><p>For more details, please see the <a href="/docs/latest/design/deep-storage">Deep storage</a> page.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="metadata-storage">Metadata storage<a href="#metadata-storage" class="hash-link" aria-label="Direct link to Metadata storage" title="Direct link to Metadata storage">​</a></h3><p>The metadata storage holds various shared system metadata such as segment usage information and task information. In a
clustered deployment, this is typically a traditional RDBMS like PostgreSQL or MySQL. In a single-server
deployment, it is typically a locally-stored Apache Derby database.</p><p>For more details, please see the <a href="/docs/latest/design/metadata-storage">Metadata storage</a> page.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="zookeeper">ZooKeeper<a href="#zookeeper" class="hash-link" aria-label="Direct link to ZooKeeper" title="Direct link to ZooKeeper">​</a></h3><p>Used for internal service discovery, coordination, and leader election.</p><p>For more details, please see the <a href="/docs/latest/design/zookeeper">ZooKeeper</a> page.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="storage-design">Storage design<a href="#storage-design" class="hash-link" aria-label="Direct link to Storage design" title="Direct link to Storage design">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="datasources-and-segments">Datasources and segments<a href="#datasources-and-segments" class="hash-link" aria-label="Direct link to Datasources and segments" title="Direct link to Datasources and segments">​</a></h3><p>Druid data is stored in <em>datasources</em>, which are similar to tables in a traditional RDBMS. Each datasource is
partitioned by time and, optionally, further partitioned by other attributes. Each time range is called a <em>chunk</em> (for
example, a single day, if your datasource is partitioned by day). Within a chunk, data is partitioned into one or more
<a href="/docs/latest/design/segments"><em>segments</em></a>. Each segment is a single file, typically comprising up to a few million rows of data. Since segments are
organized into time chunks, it&#x27;s sometimes helpful to think of segments as living on a timeline like the following:</p><p><img loading="lazy" alt="Segment timeline" src="/assets/images/druid-timeline-1eb095729ad3c5084dc7ff60aad39421.png" width="1548" height="535" class="img_ev3q"></p><p>A datasource may have anywhere from just a few segments, up to hundreds of thousands and even millions of segments. Each
segment is created by a MiddleManager as <em>mutable</em> and <em>uncommitted</em>. Data is queryable as soon as it is added to
an uncommitted segment. The segment
building process accelerates later queries by producing a data file that is compact and indexed:</p><ul><li>Conversion to columnar format</li><li>Indexing with bitmap indexes</li><li>Compression<ul><li>Dictionary encoding with id storage minimization for String columns</li><li>Bitmap compression for bitmap indexes</li><li>Type-aware compression for all columns</li></ul></li></ul><p>Periodically, segments are <em>committed</em> and <em>published</em> to <a href="#deep-storage">deep storage</a>,
become immutable, and move from MiddleManagers to the Historical processes. An entry about the segment is also written
to the <a href="#metadata-storage">metadata store</a>. This entry is a self-describing bit of metadata about the segment, including
things like the schema of the segment, its size, and its location on deep storage. These entries tell the
Coordinator what data is available on the cluster.</p><p>For details on the segment file format, please see <a href="/docs/latest/design/segments">segment files</a>.</p><p>For details on modeling your data in Druid, see <a href="/docs/latest/ingestion/schema-design">schema design</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="indexing-and-handoff">Indexing and handoff<a href="#indexing-and-handoff" class="hash-link" aria-label="Direct link to Indexing and handoff" title="Direct link to Indexing and handoff">​</a></h3><p><em>Indexing</em> is the mechanism by which new segments are created, and <em>handoff</em> is the mechanism by which they are published
and begin being served by Historical processes. On the indexing side:</p><ol><li>An <em>indexing task</em> starts running and building a new segment. It must determine the identifier of the segment before
it starts building it. For a task that is appending (like a Kafka task, or an index task in append mode) this is
done by calling an &quot;allocate&quot; API on the Overlord to potentially add a new partition to an existing set of segments. For
a task that is overwriting (like a Hadoop task, or an index task <em>not</em> in append mode) this is done by locking an
interval and creating a new version number and new set of segments.</li><li>If the indexing task is a realtime task (like a Kafka task) then the segment is immediately queryable at this point.
It&#x27;s available, but unpublished.</li><li>When the indexing task has finished reading data for the segment, it pushes it to deep storage and then publishes it
by writing a record into the metadata store.</li><li>If the indexing task is a realtime task, then to ensure data is continuously available for queries, it waits for a Historical process to load the segment. If the
indexing task is not a realtime task, it exits immediately.</li></ol><p>On the Coordinator / Historical side:</p><ol><li>The Coordinator polls the metadata store periodically (by default, every 1 minute) for newly published segments.</li><li>When the Coordinator finds a segment that is published and used, but unavailable, it chooses a Historical process
to load that segment and instructs that Historical to do so.</li><li>The Historical loads the segment and begins serving it.</li><li>At this point, if the indexing task was waiting for handoff, it will exit.</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="segment-identifiers">Segment identifiers<a href="#segment-identifiers" class="hash-link" aria-label="Direct link to Segment identifiers" title="Direct link to Segment identifiers">​</a></h3><p>Segments all have a four-part identifier with the following components:</p><ul><li>Datasource name.</li><li>Time interval (for the time chunk containing the segment; this corresponds to the <code>segmentGranularity</code> specified
at ingestion time).</li><li>Version number (generally an ISO8601 timestamp corresponding to when the segment set was first started).</li><li>Partition number (an integer, unique within a datasource+interval+version; may not necessarily be contiguous).</li></ul><p>For example, this is the identifier for a segment in datasource <code>clarity-cloud0</code>, time chunk
<code>2018-05-21T16:00:00.000Z/2018-05-21T17:00:00.000Z</code>, version <code>2018-05-21T15:56:09.909Z</code>, and partition number 1:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">clarity-cloud0_2018-05-21T16:00:00.000Z_2018-05-21T17:00:00.000Z_2018-05-21T15:56:09.909Z_1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Segments with partition number 0 (the first partition in a chunk) omit the partition number, like the following
example, which is a segment in the same time chunk as the previous one, but with partition number 0 instead of 1:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">clarity-cloud0_2018-05-21T16:00:00.000Z_2018-05-21T17:00:00.000Z_2018-05-21T15:56:09.909Z</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="segment-versioning">Segment versioning<a href="#segment-versioning" class="hash-link" aria-label="Direct link to Segment versioning" title="Direct link to Segment versioning">​</a></h3><p>You may be wondering what the &quot;version number&quot; described in the previous section is for. Or, you might not be, in which
case good for you and you can skip this section!</p><p>The version number provides a form of <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control" target="_blank" rel="noopener noreferrer"><em>multi-version concurrency control</em></a> (MVCC) to
support batch-mode overwriting. If all you ever do is append data, then there will be just a
single version for each time chunk. But when you overwrite data, Druid will seamlessly switch from
querying the old version to instead query the new, updated versions. Specifically, a new set of
segments is created with the same datasource, same time interval, but a higher version number. This is a signal to the
rest of the Druid system that the older version should be removed from the cluster, and the new version should replace
it.</p><p>The switch appears to happen instantaneously to a user, because Druid handles this by first loading the new data (but
not allowing it to be queried), and then, as soon as the new data is all loaded, switching all new queries to use those
new segments. Then it drops the old segments a few minutes later.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="segment-lifecycle">Segment lifecycle<a href="#segment-lifecycle" class="hash-link" aria-label="Direct link to Segment lifecycle" title="Direct link to Segment lifecycle">​</a></h3><p>Each segment has a lifecycle that involves the following three major areas:</p><ol><li><strong>Metadata store:</strong> Segment metadata (a small JSON payload generally no more than a few KB) is stored in the
<a href="/docs/latest/design/metadata-storage">metadata store</a> once a segment is done being constructed. The act of inserting
a record for a segment into the metadata store is called <em>publishing</em>. These metadata records have a boolean flag
named <code>used</code>, which controls whether the segment is intended to be queryable or not. Segments created by realtime tasks will be
available before they are published, since they are only published when the segment is complete and will not accept
any additional rows of data.</li><li><strong>Deep storage:</strong> Segment data files are pushed to deep storage once a segment is done being constructed. This
happens immediately before publishing metadata to the metadata store.</li><li><strong>Availability for querying:</strong> Segments are available for querying on some Druid data server, like a realtime task, directly from deep storage, or a Historical process.</li></ol><p>You can inspect the state of currently active segments using the Druid SQL
<a href="/docs/latest/querying/sql-metadata-tables#segments-table"><code>sys.segments</code> table</a>. It includes the following flags:</p><ul><li><code>is_published</code>: True if segment metadata has been published to the metadata store and <code>used</code> is true.</li><li><code>is_available</code>: True if the segment is currently available for querying, either on a realtime task or Historical
process.</li><li><code>is_realtime</code>: True if the segment is <em>only</em> available on realtime tasks. For datasources that use realtime ingestion,
this will generally start off <code>true</code> and then become <code>false</code> as the segment is published and handed off.</li><li><code>is_overshadowed</code>: True if the segment is published (with <code>used</code> set to true) and is fully overshadowed by some other
published segments. Generally this is a transient state, and segments in this state will soon have their <code>used</code> flag
automatically set to false.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="availability-and-consistency">Availability and consistency<a href="#availability-and-consistency" class="hash-link" aria-label="Direct link to Availability and consistency" title="Direct link to Availability and consistency">​</a></h3><p>Druid has an architectural separation between ingestion and querying, as described above in
<a href="#indexing-and-handoff">Indexing and handoff</a>. This means that when understanding Druid&#x27;s availability and
consistency properties, we must look at each function separately.</p><p>On the <strong>ingestion side</strong>, Druid&#x27;s primary <a href="/docs/latest/ingestion/#ingestion-methods">ingestion methods</a> are all
pull-based and offer transactional guarantees. This means that you are guaranteed that ingestion using these
methods will publish in an all-or-nothing manner:</p><ul><li>Supervised &quot;seekable-stream&quot; ingestion methods like <a href="/docs/latest/development/extensions-core/kafka-ingestion">Kafka</a> and
<a href="/docs/latest/development/extensions-core/kinesis-ingestion">Kinesis</a>. With these methods, Druid commits stream offsets to its
<a href="#metadata-storage">metadata store</a> alongside segment metadata, in the same transaction. Note that ingestion of data
that has not yet been published can be rolled back if ingestion tasks fail. In this case, partially-ingested data is
discarded, and Druid will resume ingestion from the last committed set of stream offsets. This ensures exactly-once
publishing behavior.</li><li><a href="/docs/latest/ingestion/hadoop">Hadoop-based batch ingestion</a>. Each task publishes all segment metadata in a single
transaction.</li><li><a href="/docs/latest/ingestion/native-batch">Native batch ingestion</a>. In parallel mode, the supervisor task publishes all segment
metadata in a single transaction after the subtasks are finished. In simple (single-task) mode, the single task
publishes all segment metadata in a single transaction after it is complete.</li></ul><p>Additionally, some ingestion methods offer an <em>idempotency</em> guarantee. This means that repeated executions of the same
ingestion will not cause duplicate data to be ingested:</p><ul><li>Supervised &quot;seekable-stream&quot; ingestion methods like <a href="/docs/latest/development/extensions-core/kafka-ingestion">Kafka</a> and
<a href="/docs/latest/development/extensions-core/kinesis-ingestion">Kinesis</a> are idempotent due to the fact that stream offsets and
segment metadata are stored together and updated in lock-step.</li><li><a href="/docs/latest/ingestion/hadoop">Hadoop-based batch ingestion</a> is idempotent unless one of your input sources
is the same Druid datasource that you are ingesting into. In this case, running the same task twice is non-idempotent,
because you are adding to existing data instead of overwriting it.</li><li><a href="/docs/latest/ingestion/native-batch">Native batch ingestion</a> is idempotent unless
<a href="/docs/latest/ingestion/native-batch"><code>appendToExisting</code></a> is true, or one of your input sources is the same Druid datasource
that you are ingesting into. In either of these two cases, running the same task twice is non-idempotent, because you
are adding to existing data instead of overwriting it.</li></ul><p>On the <strong>query side</strong>, the Druid Broker is responsible for ensuring that a consistent set of segments is involved in a
given query. It selects the appropriate set of segment versions to use when the query starts based on what is currently
available. This is supported by <em>atomic replacement</em>, a feature that ensures that from a user&#x27;s perspective, queries
flip instantaneously from an older version of data to a newer set of data, with no consistency or performance impact.
(See <a href="#segment-versioning">segment versioning</a> above.)
This is used for Hadoop-based batch ingestion, native batch ingestion when <code>appendToExisting</code> is false, and compaction.</p><p>Note that atomic replacement happens for each time chunk individually. If a batch ingestion task or compaction
involves multiple time chunks, then each time chunk will undergo atomic replacement soon after the task finishes, but
the replacements will not all happen simultaneously.</p><p>Typically, atomic replacement in Druid is based on a <em>core set</em> concept that works in conjunction with segment versions.
When a time chunk is overwritten, a new core set of segments is created with a higher version number. The core set
must <em>all</em> be available before the Broker will use them instead of the older set. There can also only be one core set
per version per time chunk. Druid will also only use a single version at a time per time chunk. Together, these
properties provide Druid&#x27;s atomic replacement guarantees.</p><p>Druid also supports an experimental <em>segment locking</em> mode that is activated by setting
<a href="/docs/latest/ingestion/tasks#context"><code>forceTimeChunkLock</code></a> to false in the context of an ingestion task. In this case, Druid
creates an <em>atomic update group</em> using the existing version for the time chunk, instead of creating a new core set
with a new version number. There can be multiple atomic update groups with the same version number per time chunk. Each
one replaces a specific set of earlier segments in the same time chunk and with the same version number. Druid will
query the latest one that is fully available. This is a more powerful version of the core set concept, because it
enables atomically replacing a subset of data for a time chunk, as well as doing atomic replacement and appending
simultaneously.</p><p>If segments become unavailable due to multiple Historicals going offline simultaneously (beyond your replication
factor), then Druid queries will include only the segments that are still available. In the background, Druid will
reload these unavailable segments on other Historicals as quickly as possible, at which point they will be included in
queries again.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="query-processing">Query processing<a href="#query-processing" class="hash-link" aria-label="Direct link to Query processing" title="Direct link to Query processing">​</a></h2><p>Queries are distributed across the Druid cluster, and managed by a Broker.
Queries first enter the <a href="/docs/latest/design/broker">Broker</a>, which identifies the segments with data that may pertain to that query.
The list of segments is always pruned by time, and may also be pruned by other attributes depending on how your
datasource is partitioned. The Broker will then identify which <a href="/docs/latest/design/historical">Historicals</a> and
<a href="/docs/latest/design/middlemanager">MiddleManagers</a> are serving those segments and distributes a rewritten subquery to each of those processes.
The Historical/MiddleManager processes execute each subquery and return results to the Broker. The Broker merges the partial results
to get the final answer, which it returns to the original caller.</p><p>Time and attribute pruning is an important way that Druid limits the amount of data that must be scanned for each query, but it is
not the only way. For filters at a more granular level than what the Broker can use for pruning,
<a href="#datasources-and-segments">indexing structures</a>
inside each segment allow Historicals to figure out which (if any) rows match the filter set before looking at any row of
data. Once a Historical knows which rows match a particular query, it only accesses the specific rows and columns it needs for that
query.</p><p>So Druid uses three different techniques to maximize query performance:</p><ul><li>Pruning the set of segments accessed for a query.</li><li>Within each segment, using indexes to identify which rows must be accessed.</li><li>Within each segment, only reading the specific rows and columns that are relevant to a particular query.</li></ul><p>For more details about how Druid executes queries, refer to the <a href="/docs/latest/querying/query-execution">Query execution</a>
documentation.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/tutorials/tutorial-jdbc"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">JDBC connector</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/design/segments"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Segments</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#druid-architecture" class="table-of-contents__link toc-highlight">Druid architecture</a></li><li><a href="#druid-services" class="table-of-contents__link toc-highlight">Druid services</a></li><li><a href="#druid-servers" class="table-of-contents__link toc-highlight">Druid servers</a></li><li><a href="#external-dependencies" class="table-of-contents__link toc-highlight">External dependencies</a><ul><li><a href="#deep-storage" class="table-of-contents__link toc-highlight">Deep storage</a></li><li><a href="#metadata-storage" class="table-of-contents__link toc-highlight">Metadata storage</a></li><li><a href="#zookeeper" class="table-of-contents__link toc-highlight">ZooKeeper</a></li></ul></li><li><a href="#storage-design" class="table-of-contents__link toc-highlight">Storage design</a><ul><li><a href="#datasources-and-segments" class="table-of-contents__link toc-highlight">Datasources and segments</a></li><li><a href="#indexing-and-handoff" class="table-of-contents__link toc-highlight">Indexing and handoff</a></li><li><a href="#segment-identifiers" class="table-of-contents__link toc-highlight">Segment identifiers</a></li><li><a href="#segment-versioning" class="table-of-contents__link toc-highlight">Segment versioning</a></li><li><a href="#segment-lifecycle" class="table-of-contents__link toc-highlight">Segment lifecycle</a></li><li><a href="#availability-and-consistency" class="table-of-contents__link toc-highlight">Availability and consistency</a></li></ul></li><li><a href="#query-processing" class="table-of-contents__link toc-highlight">Query processing</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="margin-bottom--sm"><img src="/img/favicon.png" class="themedImage_ToTc themedImage--light_HNdA footer__logo"><img src="/img/favicon.png" class="themedImage_ToTc themedImage--dark_i4oU footer__logo"></div><div class="footer__copyright">Copyright © 2023 Apache Software Foundation. Except where otherwise noted, licensed under CC BY-SA 4.0. Apache Druid, Druid, and the Druid logo are either registered trademarks or trademarks of The Apache Software Foundation in the United States and other countries.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.91da3985.js"></script>
<script src="/assets/js/main.1f0e5e69.js"></script>
</body>
</html>