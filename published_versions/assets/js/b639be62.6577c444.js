"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[6384],{28453:(e,n,r)=>{r.d(n,{R:()=>d,x:()=>o});var t=r(96540);const s={},i=t.createContext(s);function d(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),t.createElement(i.Provider,{value:n},e.children)}},58424:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>d,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"querying/scan-query","title":"Scan queries","description":"\x3c!--","source":"@site/docs/latest/querying/scan-query.md","sourceDirName":"querying","slug":"/querying/scan-query","permalink":"/docs/latest/querying/scan-query","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"scan-query","title":"Scan queries","sidebar_label":"Scan"},"sidebar":"docs","previous":{"title":"GroupBy","permalink":"/docs/latest/querying/groupbyquery"},"next":{"title":"Search","permalink":"/docs/latest/querying/searchquery"}}');var s=r(74848),i=r(28453);const d={id:"scan-query",title:"Scan queries",sidebar_label:"Scan"},o=void 0,a={},l=[{value:"Example results",id:"example-results",level:2},{value:"Time ordering",id:"time-ordering",level:2},{value:"Configuration Properties",id:"configuration-properties",level:2},{value:"Query context properties",id:"query-context-properties",level:2},{value:"Legacy mode",id:"legacy-mode",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["Apache Druid supports two query languages: ",(0,s.jsx)(n.a,{href:"/docs/latest/querying/sql",children:"Druid SQL"})," and ",(0,s.jsx)(n.a,{href:"/docs/latest/querying/",children:"native queries"}),".\nThis document describes a query\ntype in the native language. For information about when Druid SQL will use this query type, refer to the\n",(0,s.jsx)(n.a,{href:"/docs/latest/querying/sql-translation#query-types",children:"SQL documentation"}),"."]})}),"\n",(0,s.jsx)(n.p,{children:"The Scan query returns raw Apache Druid rows in streaming mode."}),"\n",(0,s.jsx)(n.p,{children:"In addition to straightforward usage where a Scan query is issued to the Broker, the Scan query can also be issued\ndirectly to Historical processes or streaming ingestion tasks. This can be useful if you want to retrieve large\namounts of data in parallel."}),"\n",(0,s.jsx)(n.p,{children:"An example Scan query object is shown below:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:' {\n   "queryType": "scan",\n   "dataSource": "wikipedia",\n   "resultFormat": "list",\n   "columns":[ "__time", "isRobot", "page","added", "isAnonymous", "user", "deleted" ],\n   "intervals": [\n     "2016-01-01/2017-01-02"\n   ],\n   "batchSize":20480,\n   "limit":2\n }\n'})}),"\n",(0,s.jsx)(n.p,{children:"The following are the main parameters for Scan queries:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"property"}),(0,s.jsx)(n.th,{children:"description"}),(0,s.jsx)(n.th,{children:"required?"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"queryType"}),(0,s.jsx)(n.td,{children:'This String should always be "scan"; this is the first thing Druid looks at to figure out how to interpret the query'}),(0,s.jsx)(n.td,{children:"yes"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"dataSource"}),(0,s.jsxs)(n.td,{children:["A String or Object defining the data source to query, very similar to a table in a relational database. See ",(0,s.jsx)(n.a,{href:"/docs/latest/querying/datasource",children:"DataSource"})," for more information."]}),(0,s.jsx)(n.td,{children:"yes"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"intervals"}),(0,s.jsx)(n.td,{children:"A JSON Object representing ISO-8601 Intervals. This defines the time ranges to run the query over."}),(0,s.jsx)(n.td,{children:"yes"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"resultFormat"}),(0,s.jsxs)(n.td,{children:["How the results are represented: list, compactedList or valueVector. Currently only ",(0,s.jsx)(n.code,{children:"list"})," and ",(0,s.jsx)(n.code,{children:"compactedList"})," are supported. Default is ",(0,s.jsx)(n.code,{children:"list"})]}),(0,s.jsx)(n.td,{children:"no"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"filter"}),(0,s.jsxs)(n.td,{children:["See ",(0,s.jsx)(n.a,{href:"/docs/latest/querying/filters",children:"Filters"})]}),(0,s.jsx)(n.td,{children:"no"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"columns"}),(0,s.jsx)(n.td,{children:"A String array of dimensions and metrics to scan. If left empty, all dimensions and metrics are returned."}),(0,s.jsx)(n.td,{children:"no"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"batchSize"}),(0,s.jsxs)(n.td,{children:["The maximum number of rows buffered before being returned to the client. Default is ",(0,s.jsx)(n.code,{children:"20480"})]}),(0,s.jsx)(n.td,{children:"no"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"limit"}),(0,s.jsx)(n.td,{children:"How many rows to return. If not specified, all rows will be returned."}),(0,s.jsx)(n.td,{children:"no"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"offset"}),(0,s.jsxs)(n.td,{children:["Skip this many rows when returning results. Skipped rows will still need to be generated internally and then discarded, meaning that raising offsets to high values can cause queries to use additional resources.",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),'Together, "limit" and "offset" can be used to implement pagination. However, note that if the underlying datasource is modified in between page fetches in ways that affect overall query results, then the different pages will not necessarily align with each other.']}),(0,s.jsx)(n.td,{children:"no"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"order"}),(0,s.jsxs)(n.td,{children:['The ordering of returned rows based on timestamp.  "ascending", "descending", and "none" (default) are supported.  Currently, "ascending" and "descending" are only supported for queries where the ',(0,s.jsx)(n.code,{children:"__time"})," column is included in the ",(0,s.jsx)(n.code,{children:"columns"})," field and the requirements outlined in the ",(0,s.jsx)(n.a,{href:"#time-ordering",children:"time ordering"})," section are met."]}),(0,s.jsx)(n.td,{children:"none"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"context"}),(0,s.jsxs)(n.td,{children:["An additional JSON Object which can be used to specify certain flags (see the ",(0,s.jsx)(n.code,{children:"query context properties"})," section below)."]}),(0,s.jsx)(n.td,{children:"no"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"example-results",children:"Example results"}),"\n",(0,s.jsxs)(n.p,{children:["The format of the result when resultFormat equals ",(0,s.jsx)(n.code,{children:"list"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:' [ {\n  "segmentId" : "wikipedia_2016-06-27T00:00:00.000Z_2016-06-28T00:00:00.000Z_2024-12-17T13:08:03.142Z",\n  "columns" : [ "__time", "isRobot", "page","added", "isAnonymous", "user", "deleted" ],\n  "events" : [ {\n    "__time" : 1466985611080,\n    "isRobot" : "true",\n    "page" : "Salo Toraut",\n    "added" : 31,\n    "isAnonymous" : "false",\n    "user" : "Lsjbot",\n    "deleted" : 0\n  }, {\n    "__time" : 1466985634959,\n    "isRobot" : "false",\n    "page" : "Bailando 2015",\n    "added" : 2,\n    "isAnonymous" : "true",\n    "user" : "181.230.118.178",\n    "deleted" : 0\n  } ],\n  "rowSignature" : [ {\n    "name" : "__time",\n    "type" : "LONG"\n  }, {\n    "name" : "isRobot",\n    "type" : "STRING"\n  }, {\n    "name" : "page",\n    "type" : "STRING"\n  }, {\n    "name" : "added",\n    "type" : "LONG"\n  }, {\n    "name" : "isAnonymous",\n    "type" : "STRING"\n  }, {\n    "name" : "user",\n    "type" : "STRING"\n  }, {\n    "name" : "deleted",\n    "type" : "LONG"\n  } ]\n} ]\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The format of the result when resultFormat equals ",(0,s.jsx)(n.code,{children:"compactedList"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:' [ {\n  "segmentId" : "wikipedia_2016-06-27T00:00:00.000Z_2016-06-28T00:00:00.000Z_2024-12-17T13:08:03.142Z",\n  "columns" : [ "__time", "isRobot", "isUnpatrolled", "page","added", "isNew", "delta", "isAnonymous", "user", "deleted", "namespace" ],\n  "events" : [\n    [ 1466985611080, "true", "Salo Toraut", 31, "false", "Lsjbot", 0 ],\n    [ 1466985634959, "false", "Bailando 2015", 2, "true", "181.230.118.178", 0]\n  ],\n  "rowSignature" : [ {\n    "name" : "__time",\n    "type" : "LONG"\n  }, {\n    "name" : "isRobot",\n    "type" : "STRING"\n  }, {\n    "name" : "page",\n    "type" : "STRING"\n  }, {\n    "name" : "added",\n    "type" : "LONG"\n  }, {\n    "name" : "isAnonymous",\n    "type" : "STRING"\n  }, {\n    "name" : "user",\n    "type" : "STRING"\n  }, {\n    "name" : "deleted",\n    "type" : "LONG"\n  } ]\n} ]\n'})}),"\n",(0,s.jsx)(n.h2,{id:"time-ordering",children:"Time ordering"}),"\n",(0,s.jsxs)(n.p,{children:["The Scan query currently supports ordering based on timestamp.  Note that using time ordering will yield results that\ndo not indicate which segment rows are from (",(0,s.jsx)(n.code,{children:"segmentId"})," will show up as ",(0,s.jsx)(n.code,{children:"null"}),").  Furthermore, time ordering is only\nsupported where the result set limit is less than ",(0,s.jsx)(n.code,{children:"druid.query.scan.maxRowsQueuedForOrdering"})," rows ",(0,s.jsx)(n.strong,{children:"or"})," all segments\nscanned have fewer than ",(0,s.jsx)(n.code,{children:"druid.query.scan.maxSegmentPartitionsOrderedInMemory"})," partitions.  Also, time ordering is not\nsupported for queries issued directly to historicals unless a list of segments is specified.  The reasoning behind\nthese limitations is that the implementation of time ordering uses two strategies that can consume too much heap memory\nif left unbounded.  These strategies (listed below) are chosen on a per-Historical basis depending on query result set\nlimit and the number of segments being scanned."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Priority Queue: Each segment on a Historical is opened sequentially.  Every row is added to a bounded priority\nqueue which is ordered by timestamp.  For every row above the result set limit, the row with the earliest (if descending)\nor latest (if ascending) timestamp will be dequeued.  After every row has been processed, the sorted contents of the\npriority queue are streamed back to the Broker(s) in batches.  Attempting to load too many rows into memory runs the\nrisk of Historical nodes running out of memory.  The ",(0,s.jsx)(n.code,{children:"druid.query.scan.maxRowsQueuedForOrdering"})," property protects\nfrom this by limiting the number of rows in the query result set when time ordering is used."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["N-Way Merge: For each segment, each partition is opened in parallel.  Since each partition's rows are already\ntime-ordered, an n-way merge can be performed on the results from each partition.  This approach doesn't persist the entire\nresult set in memory (like the Priority Queue) as it streams back batches as they are returned from the merge function.\nHowever, attempting to query too many partition could also result in high memory usage due to the need to open\ndecompression and decoding buffers for each.  The ",(0,s.jsx)(n.code,{children:"druid.query.scan.maxSegmentPartitionsOrderedInMemory"})," limit protects\nfrom this by capping the number of partitions opened at any times when time ordering is used."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Both ",(0,s.jsx)(n.code,{children:"druid.query.scan.maxRowsQueuedForOrdering"})," and ",(0,s.jsx)(n.code,{children:"druid.query.scan.maxSegmentPartitionsOrderedInMemory"})," are\nconfigurable and can be tuned based on hardware specs and number of dimensions being queried.  These config properties\ncan also be overridden using the ",(0,s.jsx)(n.code,{children:"maxRowsQueuedForOrdering"})," and ",(0,s.jsx)(n.code,{children:"maxSegmentPartitionsOrderedInMemory"})," properties in\nthe query context (see the Query Context Properties section)."]}),"\n",(0,s.jsx)(n.h2,{id:"configuration-properties",children:"Configuration Properties"}),"\n",(0,s.jsx)(n.p,{children:"Configuration properties:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"property"}),(0,s.jsx)(n.th,{children:"description"}),(0,s.jsx)(n.th,{children:"values"}),(0,s.jsx)(n.th,{children:"default"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"druid.query.scan.maxRowsQueuedForOrdering"}),(0,s.jsx)(n.td,{children:"The maximum number of rows returned when time ordering is used"}),(0,s.jsx)(n.td,{children:"An integer in [1, 2147483647]"}),(0,s.jsx)(n.td,{children:"100000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"druid.query.scan.maxSegmentPartitionsOrderedInMemory"}),(0,s.jsx)(n.td,{children:"The maximum number of segments scanned per historical when time ordering is used"}),(0,s.jsx)(n.td,{children:"An integer in [1, 2147483647]"}),(0,s.jsx)(n.td,{children:"50"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"query-context-properties",children:"Query context properties"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"property"}),(0,s.jsx)(n.th,{children:"description"}),(0,s.jsx)(n.th,{children:"values"}),(0,s.jsx)(n.th,{children:"default"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"maxRowsQueuedForOrdering"}),(0,s.jsx)(n.td,{children:"The maximum number of rows returned when time ordering is used.  Overrides the identically named config."}),(0,s.jsx)(n.td,{children:"An integer in [1, 2147483647]"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"druid.query.scan.maxRowsQueuedForOrdering"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"maxSegmentPartitionsOrderedInMemory"}),(0,s.jsx)(n.td,{children:"The maximum number of segments scanned per historical when time ordering is used.  Overrides the identically named config."}),(0,s.jsx)(n.td,{children:"An integer in [1, 2147483647]"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"druid.query.scan.maxSegmentPartitionsOrderedInMemory"})})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"Sample query context JSON object:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "maxRowsQueuedForOrdering": 100001,\n  "maxSegmentPartitionsOrderedInMemory": 100\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"legacy-mode",children:"Legacy mode"}),"\n",(0,s.jsx)(n.p,{children:"In older versions of Druid, the scan query supported a legacy mode designed for protocol compatibility with the former scan-query contrib extension from versions of Druid older than 0.11. This mode has been removed."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);