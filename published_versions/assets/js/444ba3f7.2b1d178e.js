"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[9231],{28453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>l});var a=r(96540);const t={},s=a.createContext(t);function i(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),a.createElement(s.Provider,{value:n},e.children)}},77724:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"operations/rolling-updates","title":"Rolling updates","description":"\x3c!--","source":"@site/docs/33.0.0/operations/rolling-updates.md","sourceDirName":"operations","slug":"/operations/rolling-updates","permalink":"/docs/33.0.0/operations/rolling-updates","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"rolling-updates","title":"Rolling updates"},"sidebar":"docs","previous":{"title":"High availability","permalink":"/docs/33.0.0/operations/high-availability"},"next":{"title":"Using rules to drop and retain data","permalink":"/docs/33.0.0/operations/rule-configuration"}}');var t=r(74848),s=r(28453);const i={id:"rolling-updates",title:"Rolling updates"},l=void 0,o={},d=[{value:"Historical",id:"historical",level:2},{value:"Overlord",id:"overlord",level:2},{value:"Middle Managers/Indexers",id:"middle-managersindexers",level:2},{value:"Rolling restart (restore-based)",id:"rolling-restart-restore-based",level:3},{value:"Rolling restart (graceful-termination-based)",id:"rolling-restart-graceful-termination-based",level:3},{value:"Autoscaling-based replacement",id:"autoscaling-based-replacement",level:3},{value:"Standalone Real-time",id:"standalone-real-time",level:2},{value:"Broker",id:"broker",level:2},{value:"Coordinator",id:"coordinator",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"For rolling Apache Druid cluster updates with no downtime, we recommend updating Druid processes in the\nfollowing order:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Historical"}),"\n",(0,t.jsx)(n.li,{children:"Middle Manager and Indexer (if any)"}),"\n",(0,t.jsx)(n.li,{children:"Broker"}),"\n",(0,t.jsx)(n.li,{children:"Router"}),"\n",(0,t.jsxs)(n.li,{children:["Overlord (Note that you can upgrade the Overlord before any Middle Manager processes if you use ",(0,t.jsx)(n.a,{href:"#autoscaling-based-replacement",children:"autoscaling-based replacement"}),".)"]}),"\n",(0,t.jsx)(n.li,{children:"Coordinator ( or merged Coordinator+Overlord )"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"If you need to do a rolling downgrade, reverse the order and start with the Coordinator processes."}),"\n",(0,t.jsxs)(n.p,{children:["For information about the latest release, see ",(0,t.jsx)(n.a,{href:"https://github.com/apache/druid/releases",children:"Druid releases"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"historical",children:"Historical"}),"\n",(0,t.jsx)(n.p,{children:"Historical processes can be updated one at a time. Each Historical process has a startup time to memory map\nall the segments it was serving before the update. The startup time typically takes a few seconds to\na few minutes, depending on the hardware of the host. As long as each Historical process is updated\nwith a sufficient delay (greater than the time required to start a single process), you can rolling\nupdate the entire Historical cluster."}),"\n",(0,t.jsx)(n.h2,{id:"overlord",children:"Overlord"}),"\n",(0,t.jsx)(n.p,{children:"Overlord processes can be updated one at a time in a rolling fashion."}),"\n",(0,t.jsx)(n.h2,{id:"middle-managersindexers",children:"Middle Managers/Indexers"}),"\n",(0,t.jsx)(n.p,{children:"Middle Managers or Indexer nodes run both batch and real-time indexing tasks. Generally you want to update Middle\nManagers in such a way that real-time indexing tasks do not fail. There are three strategies for\ndoing that."}),"\n",(0,t.jsx)(n.h3,{id:"rolling-restart-restore-based",children:"Rolling restart (restore-based)"}),"\n",(0,t.jsxs)(n.p,{children:["Middle Managers can be updated one at a time in a rolling fashion when you set\n",(0,t.jsx)(n.code,{children:"druid.indexer.task.restoreTasksOnRestart=true"}),". In this case, indexing tasks that support restoring\nwill restore their state on Middle Manager restart, and will not fail."]}),"\n",(0,t.jsx)(n.p,{children:"Currently, only realtime tasks support restoring, so non-realtime indexing tasks will fail and will\nneed to be resubmitted."}),"\n",(0,t.jsx)(n.h3,{id:"rolling-restart-graceful-termination-based",children:"Rolling restart (graceful-termination-based)"}),"\n",(0,t.jsx)(n.p,{children:'Middle Managers can be gracefully terminated using the "disable" API. This works for all task types,\neven tasks that are not restorable.'}),"\n",(0,t.jsxs)(n.p,{children:["To prepare a Middle Manager for update, send a POST request to\n",(0,t.jsx)(n.code,{children:"<Middle_Manager_IP:PORT>/druid/worker/v1/disable"}),". The Overlord will now no longer send tasks to\nthis Middle Manager. Tasks that have already started will run to completion. Current state can be checked\nusing ",(0,t.jsx)(n.code,{children:"<Middle_Manager_IP:PORT>/druid/worker/v1/enabled"})," ."]}),"\n",(0,t.jsxs)(n.p,{children:["To view all existing tasks, send a GET request to ",(0,t.jsx)(n.code,{children:"<Middle_Manager_IP:PORT>/druid/worker/v1/tasks"}),".\nWhen this list is empty, you can safely update the Middle Manager. After the Middle Manager starts\nback up, it is automatically enabled again. You can also manually enable Middle Managers by POSTing\nto ",(0,t.jsx)(n.code,{children:"<Middle_Manager_IP:PORT>/druid/worker/v1/enable"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"autoscaling-based-replacement",children:"Autoscaling-based replacement"}),"\n",(0,t.jsxs)(n.p,{children:["If autoscaling is enabled on your Overlord, then Overlord processes can launch new Middle Manager processes\nen masse and then gracefully terminate old ones as their tasks finish. This process is configured by\nsetting ",(0,t.jsx)(n.code,{children:"druid.indexer.runner.minWorkerVersion=#{VERSION}"}),". Each time you update your Overlord process,\nthe ",(0,t.jsx)(n.code,{children:"VERSION"})," value should be increased, which will trigger a mass launch of new Middle Managers."]}),"\n",(0,t.jsxs)(n.p,{children:["The config ",(0,t.jsx)(n.code,{children:"druid.indexer.autoscale.workerVersion=#{VERSION}"})," also needs to be set."]}),"\n",(0,t.jsx)(n.h2,{id:"standalone-real-time",children:"Standalone Real-time"}),"\n",(0,t.jsx)(n.p,{children:"Standalone real-time processes can be updated one at a time in a rolling fashion."}),"\n",(0,t.jsx)(n.h2,{id:"broker",children:"Broker"}),"\n",(0,t.jsx)(n.p,{children:"Broker processes can be updated one at a time in a rolling fashion. There needs to be some delay between\nupdating each process as Brokers must load the entire state of the cluster before they return valid\nresults."}),"\n",(0,t.jsx)(n.h2,{id:"coordinator",children:"Coordinator"}),"\n",(0,t.jsx)(n.p,{children:"Coordinator processes can be updated one at a time in a rolling fashion."})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}}}]);