"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[1921],{28453:(e,i,r)=>{r.d(i,{R:()=>s,x:()=>a});var o=r(96540);const t={},n=o.createContext(t);function s(e){const i=o.useContext(n);return o.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(n.Provider,{value:i},e.children)}},90364:(e,i,r)=>{r.r(i),r.d(i,{assets:()=>d,contentTitle:()=>a,default:()=>c,frontMatter:()=>s,metadata:()=>o,toc:()=>u});const o=JSON.parse('{"id":"release-info/migration-guide","title":"Migration guides","description":"How to migrate from legacy features to get the most from Druid updates","source":"@site/docs/33.0.0/release-info/migration-guide.md","sourceDirName":"release-info","slug":"/release-info/migration-guide","permalink":"/docs/33.0.0/release-info/migration-guide","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"migration-guide","title":"Migration guides","description":"How to migrate from legacy features to get the most from Druid updates"},"sidebar":"docs","previous":{"title":"Upgrade notes","permalink":"/docs/33.0.0/release-info/upgrade-notes"},"next":{"title":"MVDs to arrays","permalink":"/docs/33.0.0/release-info/migr-mvd-array"}}');var t=r(74848),n=r(28453);const s={id:"migration-guide",title:"Migration guides",description:"How to migrate from legacy features to get the most from Druid updates"},a=void 0,d={},u=[{value:"Migrate from multi-value dimensions to arrays",id:"migrate-from-multi-value-dimensions-to-arrays",level:2},{value:"Migrate to front-coded dictionary encoding",id:"migrate-to-front-coded-dictionary-encoding",level:2},{value:"Migrate from <code>maxSubqueryRows</code> to <code>maxSubqueryBytes</code>",id:"migrate-from-maxsubqueryrows-to-maxsubquerybytes",level:2},{value:"Migrate to SQL compliant null handling mode",id:"migrate-to-sql-compliant-null-handling-mode",level:2}];function l(e){const i={a:"a",code:"code",h2:"h2",p:"p",...(0,n.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.p,{children:"In general, when we introduce new features and behaviors into Apache Druid, we make every effort to avoid breaking existing features when introducing new behaviors. However, sometimes there are either bugs or performance limitations with the old behaviors that are not possible to fix in a backward-compatible way. In these cases, we must introduce breaking changes for the future maintainability of Druid."}),"\n",(0,t.jsx)(i.p,{children:"The guides in this section outline breaking changes introduced in Druid 25.0.0 and later. Each guide provides instructions to migrate to new features."}),"\n",(0,t.jsx)(i.h2,{id:"migrate-from-multi-value-dimensions-to-arrays",children:"Migrate from multi-value dimensions to arrays"}),"\n",(0,t.jsxs)(i.p,{children:["Druid now supports SQL-compliant array types. Whenever possible, you should use the array type over multi-value dimensions. See ",(0,t.jsx)(i.a,{href:"/docs/33.0.0/release-info/migr-mvd-array",children:"Migration guide: MVDs to arrays"}),"."]}),"\n",(0,t.jsx)(i.h2,{id:"migrate-to-front-coded-dictionary-encoding",children:"Migrate to front-coded dictionary encoding"}),"\n",(0,t.jsxs)(i.p,{children:["Druid encodes string columns into dictionaries for better compression. Front-coded dictionary encoding reduces storage and improves performance by optimizing for strings that share similar beginning substrings. See ",(0,t.jsx)(i.a,{href:"/docs/33.0.0/release-info/migr-front-coded-dict",children:"Migration guide: front-coded dictionaries"})," for more information."]}),"\n",(0,t.jsxs)(i.h2,{id:"migrate-from-maxsubqueryrows-to-maxsubquerybytes",children:["Migrate from ",(0,t.jsx)(i.code,{children:"maxSubqueryRows"})," to ",(0,t.jsx)(i.code,{children:"maxSubqueryBytes"})]}),"\n",(0,t.jsxs)(i.p,{children:["Druid allows you to set a byte-based limit on subquery size to prevent Brokers from running out of memory when handling large subqueries. The byte-based subquery limit overrides Druid's row-based subquery limit. We recommend that you move towards using byte-based limits starting in Druid 30.0.0. See ",(0,t.jsx)(i.a,{href:"/docs/33.0.0/release-info/migr-subquery-limit",children:"Migration guide: subquery limit"})," for more information."]}),"\n",(0,t.jsx)(i.h2,{id:"migrate-to-sql-compliant-null-handling-mode",children:"Migrate to SQL compliant null handling mode"}),"\n",(0,t.jsxs)(i.p,{children:["By default, the Druid ",(0,t.jsx)(i.a,{href:"/docs/33.0.0/querying/sql-data-types#null-values",children:"null handling"})," mode is now compliant with ANSI SQL.\nThis guide provides strategies for Druid operators and users who rely on the legacy Druid null handling behavior in their applications to transition to ANSI SQL compliant mode.  See ",(0,t.jsx)(i.a,{href:"/docs/33.0.0/release-info/migr-ansi-sql-null",children:"Migration guide: SQL compliant mode"})," for more information."]})]})}function c(e={}){const{wrapper:i}={...(0,n.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}}}]);