"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[7308],{3905:(e,r,t)=>{t.d(r,{Zo:()=>l,kt:()=>m});var n=t(67294);function a(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function i(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?i(Object(t),!0).forEach((function(r){a(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function s(e,r){if(null==e)return{};var t,n,a=function(e,r){if(null==e)return{};var t,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)t=i[n],r.indexOf(t)>=0||(a[t]=e[t]);return a}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)t=i[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var c=n.createContext({}),p=function(e){var r=n.useContext(c),t=r;return e&&(t="function"==typeof e?e(r):o(o({},r),e)),t},l=function(e){var r=p(e.components);return n.createElement(c.Provider,{value:r},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},f=n.forwardRef((function(e,r){var t=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),u=p(t),f=a,m=u["".concat(c,".").concat(f)]||u[f]||d[f]||i;return t?n.createElement(m,o(o({ref:r},l),{},{components:t})):n.createElement(m,o({ref:r},l))}));function m(e,r){var t=arguments,a=r&&r.mdxType;if("string"==typeof e||a){var i=t.length,o=new Array(i);o[0]=f;var s={};for(var c in r)hasOwnProperty.call(r,c)&&(s[c]=r[c]);s.originalType=e,s[u]="string"==typeof e?e:a,o[1]=s;for(var p=2;p<i;p++)o[p]=t[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}f.displayName="MDXCreateElement"},75580:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>l,contentTitle:()=>c,default:()=>m,frontMatter:()=>s,metadata:()=>p,toc:()=>u});var n=t(87462),a=t(63366),i=(t(67294),t(3905)),o=["components"],s={id:"druid-vs-spark",title:"Apache Druid vs Spark"},c=void 0,p={unversionedId:"comparisons/druid-vs-spark",id:"comparisons/druid-vs-spark",title:"Apache Druid vs Spark",description:"\x3c!--",source:"@site/docs/30.0.0/comparisons/druid-vs-spark.md",sourceDirName:"comparisons",slug:"/comparisons/druid-vs-spark",permalink:"/docs/30.0.0/comparisons/druid-vs-spark",draft:!1,tags:[],version:"current",frontMatter:{id:"druid-vs-spark",title:"Apache Druid vs Spark"}},l={},u=[],d={toc:u},f="wrapper";function m(e){var r=e.components,t=(0,a.Z)(e,o);return(0,i.kt)(f,(0,n.Z)({},d,t,{components:r,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Druid and Spark are complementary solutions as Druid can be used to accelerate OLAP queries in Spark."),(0,i.kt)("p",null,"Spark is a general cluster computing framework initially designed around the concept of Resilient Distributed Datasets (RDDs).\nRDDs enable data reuse by persisting intermediate results\nin memory and enable Spark to provide fast computations for iterative algorithms.\nThis is especially beneficial for certain work flows such as machine\nlearning, where the same operation may be applied over and over\nagain until some result is converged upon. The generality of Spark makes it very suitable as an engine to process (clean or transform) data.\nAlthough Spark provides the ability to query data through Spark SQL, much like Hadoop, the query latencies are not specifically targeted to be interactive (sub-second)."),(0,i.kt)("p",null,"Druid's focus is on extremely low latency queries, and is ideal for powering applications used by thousands of users, and where each query must\nreturn fast enough such that users can interactively explore through data. Druid fully indexes all data, and can act as a middle layer between Spark and your application.\nOne typical setup seen in production is to process data in Spark, and load the processed data into Druid for faster access."),(0,i.kt)("p",null,"For more information about using Druid and Spark together, including benchmarks of the two systems, please see:"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://www.linkedin.com/pulse/combining-druid-spark-interactive-flexible-analytics-scale-butani"},"https://www.linkedin.com/pulse/combining-druid-spark-interactive-flexible-analytics-scale-butani")))}m.isMDXComponent=!0}}]);